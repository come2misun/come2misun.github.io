---
layout: post
title: 모두연 풀잎반 1기 3주차
categories:
  - 모두연 풀잎반
tags:
  - cs231n
  - 풀잎반 
excerpt_separator:  <!--more-->
---

## [Week3 강의 자료들] 
### 이론 강의 : Lecture 3
Loss Functions and Optimization 
* Linear classification II
* Higher-level representations, image features
* Optimization, stochastic gradient descent


### 실습 숙제
* Assignment 1 : [Assignment #1]

 
<!--more-->
<div class="embed-responsive embed-responsive-4by3">
  <iframe width="640" height="360" src="https://www.youtube-nocookie.com/embed/h7iBpEHGVNc?controls=0&amp;" frameborder="0" allowfullscreen></iframe>
</div>


softMax vs hardMax

SVM


## 정규화 선택 
### L1과 L2의 차이 

: feature의 특징에 따라 선택
* L1 : 각각의 features에 강하게 영향을 받음
* L2



## Softmax
* exp 하는 이유
-log(x) : x는 0 ~ 1 로 변환


* cross entropy

 
* 미분을 사용하는 이유
수치미분
해석미분


## minibatch 의 단위
* 32의 배수 : 메모리 단위